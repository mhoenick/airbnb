{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "improved-danger",
   "metadata": {},
   "source": [
    "# Airbnb Seattle Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "essential-solution",
   "metadata": {},
   "source": [
    "The questions that should be reviewed in this project are: <br>\n",
    "\n",
    "    1. What are the main rental price drivers?\n",
    "    2. What are the price differences between accomodations with varying prices business days to weekends?\n",
    "    3. Are there any clear differences between accomodations with constant and varying prices. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "quarterly-excitement",
   "metadata": {},
   "source": [
    "# Data Understanding"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "boolean-dietary",
   "metadata": {},
   "source": [
    "## Libraries for complete notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "suspended-spyware",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "sized-inquiry",
   "metadata": {},
   "source": [
    "## Import available dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "after-government",
   "metadata": {},
   "outputs": [],
   "source": [
    "path_work = 'C:/Users/matze/Documents/workspace/udc_DS/airbnb'\n",
    "filenames = ['calendar', 'listings', 'reviews']\n",
    "\n",
    "\n",
    "def read_csv(name, error_bad_lines=True):\n",
    "    with open(os.path.join(path_work, name + '.csv'), 'r', errors='replace') as source:\n",
    "        df = pd.read_csv(source, header=0, parse_dates=True,\n",
    "                         dayfirst=True)#, error_bad_lines=False)\n",
    "    return df\n",
    "\n",
    "# reviews.csv data is not required for analysis\n",
    "calendar = read_csv('calendar')\n",
    "listings = read_csv('listings')\n",
    "#listings"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "german-doctrine",
   "metadata": {},
   "source": [
    "### Data preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "burning-frank",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "listing_id     int64\n",
       "date          object\n",
       "available     object\n",
       "price         object\n",
       "dtype: object"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#check calendar dtypes\n",
    "calendar.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "piano-relative",
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert calendar dtypes\n",
    "calendar['price'] = calendar['price'].map(\n",
    "    lambda x: x.lstrip('$'), na_action='ignore')\n",
    "calendar['price'] = calendar['price'].map(\n",
    "    lambda x: x.replace(',', ''), na_action='ignore')\n",
    "calendar['price'] = pd.to_numeric(calendar['price'])\n",
    "\n",
    "calendar['date'] = pd.to_datetime(calendar['date'])\n",
    "\n",
    "calendar['available'] = calendar['available'].map({'t': True, 'f': False})\n",
    "# calendar.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "opening-victoria",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "spread-accordance",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Listings data prep\n",
    "# Check for columns with np.nan only and drop\n",
    "col_nan = listings.isna().all()[listings.isna().all() == True].index\n",
    "listings = listings.drop(columns=col_nan)\n",
    "\n",
    "# Drop url's as almost all unique hence no value\n",
    "listings = listings.drop(\n",
    "    columns=[col for col in listings.columns if col[-4:] == '_url'])\n",
    "\n",
    "# Remove text columns not categorial or with many cats\n",
    "# assumption: eg streets to detailed, cleansed neighboorhoods kept\n",
    "listings = listings.drop(columns=['name', 'summary', 'space', 'description',\n",
    "                                  'neighborhood_overview', 'notes', 'transit',\n",
    "                                  'host_name', 'host_location', 'host_about',\n",
    "                                  'host_verifications', 'street', 'country_code',\n",
    "                                  'country', 'first_review', 'last_review',\n",
    "                                  'neighbourhood'])\n",
    "\n",
    "# convert objects into usable dtypes\n",
    "col_obj = listings.select_dtypes('object').columns\n",
    "for col in col_obj:\n",
    "    # print(col)\n",
    "    # Remove $ and % sign in prep to change cols to numeric dtype\n",
    "    listings[col] = listings[col].map(\n",
    "        lambda x: x.lstrip('$'), na_action='ignore')\n",
    "    listings[col] = listings[col].map(\n",
    "        lambda x: x.rstrip('%'), na_action='ignore')\n",
    "\n",
    "    # change to numeric dtype; remove thousands separator first\n",
    "    if col in ['price', 'weekly_price', 'monthly_price', 'security_deposit',\n",
    "               'cleaning_fee', 'extra_people', 'host_response_rate',\n",
    "               'host_acceptance_rate']:\n",
    "        listings[col] = listings[col].map(\n",
    "            lambda x: x.replace(',', ''), na_action='ignore')\n",
    "        listings[col] = pd.to_numeric(listings[col])\n",
    "\n",
    "    # ignore rows that start with np.nan for the moment\n",
    "    elif listings[col][0] != listings[col][0]:\n",
    "        listings[col] = listings[col]\n",
    "\n",
    "    # covert to datetimes\n",
    "    elif re.search('\\d\\d\\d\\d-\\d\\d-\\d\\d', listings[col][0]):\n",
    "        listings[col] = pd.to_datetime(listings[col])\n",
    "\n",
    "    # convert to boolean as only t and f\n",
    "    elif re.search('^[t|f]$', listings[col][0]):\n",
    "        listings[col] = listings[col].replace({'t': True, 'f': False})\n",
    "\n",
    "    # keep all others\n",
    "    else:\n",
    "        listings[col] = listings[col]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "ranging-trinidad",
   "metadata": {},
   "outputs": [],
   "source": [
    "#listings.describe(include='all',datetime_is_numeric=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "shaped-likelihood",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Amenities to be hot encoded separately as one str for all entries\n",
    "# Split into categories and remove/clean\n",
    "pat = re.compile('[{}\"]')\n",
    "df_amt = listings['amenities'].apply(lambda x: sorted(\n",
    "    [re.sub(pat, '', y) for y in x.split(',')]))\n",
    "\n",
    "# Set of all possible amenities\n",
    "amenities = []\n",
    "for each in df_amt:\n",
    "    amenities = amenities + each\n",
    "amenities = set(amenities)\n",
    "amenities.remove('')\n",
    "\n",
    "# df hot encoded amenities\n",
    "df_amt_hot = pd.DataFrame(columns=sorted(amenities), index=listings.index)\n",
    "\n",
    "for row in range(len(listings.index)):\n",
    "    for col, each in enumerate(sorted(amenities)):\n",
    "        if each in df_amt[row]:\n",
    "            df_amt_hot.iloc[row, col] = True\n",
    "        else:\n",
    "            df_amt_hot.iloc[row, col] = False\n",
    "\n",
    "# Replace amenities with hot encoded amenities inlistings\n",
    "listings = pd.concat([listings, df_amt_hot], axis=1)\n",
    "listings = listings.drop(columns=['amenities'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "married-investor",
   "metadata": {},
   "outputs": [],
   "source": [
    "#listings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "engaged-jewel",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate listings with hot encoding\n",
    "listings_dum = pd.get_dummies(listings, drop_first=True)\n",
    "#listings_dum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "challenging-harvey",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
